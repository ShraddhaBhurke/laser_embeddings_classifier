{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6872228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Having data in multiple languages so using LASER embedding which helps to map the word with same meaning in multiple languages to the closest vector.\n",
    "#using LASER embeddings even if data is less in each language the prediction model gives good accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0fd4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from laserembeddings import Laser\n",
    "import pandas as pd\n",
    "# input is the excel with columns('labels','filename','tokens','page_content','page_lang')\n",
    "source = r\"claim_doc.xlsx\"\n",
    "LANG = {\"_lang_spanish\":\"es\",\"_lang_english\":\"en\",\"_lang_portuguese\":\"pt\",\"_lang_dutch \":\"nl\",\"_lang_french\":\"fr\",\"_lang_german\":\"de\",\"_lang_italian\":\"it\"}\n",
    "data_df = pd.read_excel(source)\n",
    "#lang = data_df.group_by('page_lang')\n",
    "\n",
    "#Downloaded the laser model and referencing the path to files below\n",
    "path_to_bpe_codes = \"C:\\Project\\LASER_model\\93langs.fcodes\"\n",
    "path_to_bpe_vocab = \"C:\\Project\\LASER_model\\93langs.fvocab\"\n",
    "path_to_encoder = r\"C:\\Project\\LASER_model\\bilstm.93langs.2018-12-26.pt\"\n",
    "\n",
    "laser = Laser(path_to_bpe_codes, path_to_bpe_vocab, path_to_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86300ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d20796",
   "metadata": {},
   "outputs": [],
   "source": [
    "doctype_others = data_df[data_df[\"labels\"] == \"OTHERS\"]\n",
    "all_doc = data_df[data_df[\"labels\"] != \"OTHERS\"]\n",
    "print(doctype_others.shape)\n",
    "print(all_doc.shape)\n",
    "#print(df[\"labels\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e220b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "others_downsample = resample(doctype_others,\n",
    "             replace=True,\n",
    "             n_samples=1100,\n",
    "             random_state=42)\n",
    "\n",
    "print(others_downsample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed353f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data_downsampled = pd.concat([others_downsample,all_doc])\n",
    "data_downsampled = pd.concat([others_downsample,all_doc])\n",
    "\n",
    "print(data_downsampled[\"labels\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ae288",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data_df.replace({'page_lang' : {\"_lang_spanish\":\"es\",\"_lang_english\":\"en\",\"_lang_portuguese\":\"pt\",\"_lang_dutch \":\"nl\",\"_lang_french\":\"fr\",\"_lang_german\":\"de\",\"_lang_italian\":\"it\"}})\n",
    "content = temp[\"page_content\"]\n",
    "#print(\"content\",len(content))\n",
    "lang_page = temp[\"page_lang\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c36f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if all sentences are in the same language:\n",
    "#lang_dict = []\n",
    "#for k,v in LANG.items():\n",
    "    #one_lang = data_df.loc[data_df['page_lang'] == k]\n",
    "    #content = one_lang[\"page_content\"]\n",
    "    #lang_dict.append(content)\n",
    "temp = data_df.replace({'page_lang' : {\"_lang_spanish\":\"es\",\"_lang_english\":\"en\",\"_lang_portuguese\":\"pt\",\"_lang_dutch \":\"nl\",\"_lang_french\":\"fr\",\"_lang_german\":\"de\",\"_lang_italian\":\"it\"}})\n",
    "content = temp[\"tokens\"]\n",
    "lang_page = temp[\"page_lang\"]\n",
    "#print(lang_page)\n",
    "embeddings = laser.embed_sentences(content, lang=lang_page)  # lang is only used for tokenization\n",
    "#embedded_dict[v] = embeddings\n",
    "print(\"Embeddings:\",embeddings)\n",
    "\n",
    "# embeddings is a N*1024 (N = number of sentences) NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if all sentences are in the same language:\n",
    "#embedded_dict = {}\n",
    "for k,v in LANG.items():\n",
    "    one_lang = data_df.loc[data_df['page_lang'] == k]\n",
    "    content = one_lang[\"page_content\"]\n",
    "    embeddings = laser.embed_sentences(content, lang=v)  # lang is only used for tokenization\n",
    "    embedded_dict[v] = embeddings\n",
    "print(\"Embeddings:\",embedded_dict)\n",
    "\n",
    "# embeddings is a N*1024 (N = number of sentences) NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b65e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(embeddings, \"embeddings_claim_doc.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae8dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "embeddings = joblib.load(\"embeddings_claim_doc.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f8524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.utils import resample\n",
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29737ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=700,svd_solver=\"auto\")\n",
    "pca.fit(embeddings)\n",
    "x = pca.transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e350a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"embeddings.txt\",'w')as fp:\n",
    "    fp.write(str(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be19e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split datset into train, test dataset\n",
    "X_train_1, X_test, y_train_1, y_test = train_test_split(embeddings, temp['labels'], test_size=0.2, random_state=0)\n",
    "\n",
    "#Random oversampling and balancing the dataset\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "ros.fit(X_train_1, y_train_1)\n",
    "X_train, y_train = ros.fit_resample(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c4f287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split datset into train, test dataset\n",
    "X_train_1, X_test, y_train_1, y_test = train_test_split(embeddings, temp['labels'], test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ccac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "model_svc = LinearSVC()\n",
    "model = CalibratedClassifierCV(model_svc) \n",
    "model.fit(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_excel(r\"pred_claim.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1db0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_excel(\"pred_claim.xlsx\")\n",
    "filename_list = []\n",
    "for val in temp['Number']:\n",
    "    filename_index = data_df._get_value(val, 'filename')\n",
    "    filename_list.append(filename_index)\n",
    "l1 = pd.DataFrame(filename_list)\n",
    "l1.columns = ['filename']\n",
    "l1[\"Actual_Labels\"] = temp['labels']\n",
    "l1 ['predicted_Labels'] = lsvc_pred.tolist()\n",
    "l1.to_excel(\"temp.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c914b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "import joblib\n",
    "joblib.dump(embeddings, \"vectorizer_claim_doc.sav\")\n",
    "joblib.dump(model, \"model_claim_doc.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a738e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=0)\n",
    "model.fit(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8476416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "gradient_booster = GradientBoostingClassifier(learning_rate=0.1)\n",
    "gradient_booster.fit(X_train_1, y_train_1)\n",
    "print(classification_report(y_test,gradient_booster.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad44553",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_pred = gradient_booster.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a847f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_pred = model.predict(X_test)\n",
    "\n",
    "# get the precision, recall, f1 score, accuracy scores\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,logistic_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016601c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_pred = model.predict(X_test)\n",
    "\n",
    "# get the precision, recall, f1 score, accuracy scores\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,lsvc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cce47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "conf_mat = confusion_matrix(y_test, lsvc_pred)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',xticklabels=['CLAIM','OTHERS'], yticklabels=['CLAIM','OTHERS'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
